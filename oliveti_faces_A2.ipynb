{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of [A2] - oliveti_faces.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavSB/A5/blob/master/oliveti_faces_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlquyeZ1glnV"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.datasets.olivetti_faces import fetch_olivetti_faces\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Flatten, Dense, Activation, Dropout\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras import regularizers\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R790cEIugqMe"
      },
      "source": [
        "  \n",
        "# Fetch data and have a look\n",
        "faces = fetch_olivetti_faces()\n",
        "x, y = faces['data'], faces['target']\n",
        "\n",
        "# Dimensions\n",
        "print(f'Data shape: {x.shape}')\n",
        "print(f'Label shape: {y.shape}')\n",
        "# (400, 4096)\n",
        "# (400,)\n",
        "\n",
        "print(np.unique(y))\n",
        "\n",
        "# create a grid of 3x3 images\n",
        "for i in range(0, 9):\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    plt.imshow(x[i].reshape(64, 64))\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n",
        "# divide data into training, validation and testing (shuffle)\n",
        "#\n",
        "# Important notes:\n",
        "# test_size=0.2 Holdout. Reserves 20% of the data for testing. \n",
        "# random_state=42 provides the shuffle(randomizer) function with a seed number. \n",
        "# stratify=y will distribute the data 'equally' meaning, it samples the whole dataset. The opposite would be to say, divide the data based\n",
        "# it's meaningful representation, clustered images in this case. So of we trained on one part of the clustered imgs, and tested on the rest, \n",
        "# the model would be useless, as it would be overfitting. \n",
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "xtrain, xtest, ytrain, ytest =train_test_split(x,y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(xtrain.shape) # 80% of the pixels in an image\n",
        "print(xtest.shape) # 20% of the pixels in an image\n",
        "print(y[0:10])\n",
        "print('training data', ytrain[0:10])\n",
        "print('testing data', ytest[0:10])\n",
        "\n",
        "print(np.bincount(y)) # 10 pictures each person, 40 persons - 400 pictures. \n",
        "print(np.bincount(ytrain)) # The 8 pictures per person for training\n",
        "print(np.bincount(ytest)) # The 2 pictures for testing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hoJwhhOFB7V"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ks0ncUIN8f6"
      },
      "source": [
        "autoencoder = Sequential()\n",
        "autoencoder.add(Dense(units = 1024, activation='relu', input_dim = 4096, name='encoder_layer1'))   # encoder layers\n",
        "autoencoder.add(Dense(units = 512, activation='relu', input_dim =  1024, name='encoder_layer2'))\n",
        "autoencoder.add(Dense(units =  64, activation='relu', input_dim =  512, name='encoder_layer3'))\n",
        "\n",
        "\n",
        "autoencoder.add(Dense(units = 512, activation='relu', name='decoder_layer1'))                    # decoder layers\n",
        "autoencoder.add(Dense(units = 1024, activation='relu', name='decoder_layer2'))\n",
        "autoencoder.add(Dense(units = 4096, activation='sigmoid', name='decoder_layer3'))    #linear - softmax\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])   #mean_squared_error\n",
        "\n",
        "autoencoder.summary()\n",
        "plot_model(autoencoder, to_file='AE_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "from IPython.display import Image \n",
        "Image('AE_plot.png')\n",
        "\n",
        "history = autoencoder.fit(x = xtrain, y= xtrain, epochs=1000, batch_size=32, shuffle=True,\\\n",
        "                    validation_data=(xtrain, xtrain), verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heb5yEJlTcsS"
      },
      "source": [
        "# test trained autoencoder\n",
        "encoder = Model(inputs = autoencoder.input, outputs = autoencoder.layers[2].output)\n",
        "encoded_imgs = encoder.predict(xtest)\n",
        "\n",
        "print(encoded_imgs.shape)\n",
        "\n",
        "# retrieve the last layer of the autoencoder model\n",
        "\n",
        "encoded_input = Input(shape=(64,))\n",
        "decoder_layer = autoencoder.layers[3](encoded_input)\n",
        "decoder_layer = autoencoder.layers[4](decoder_layer)\n",
        "decoder_layer = autoencoder.layers[5](decoder_layer)\n",
        "\n",
        "decoder = Model(inputs = encoded_input, outputs = decoder_layer)\n",
        "\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "\n",
        "print(encoded_imgs.shape)\n",
        "\n",
        "predicted_imgs = autoencoder.predict(xtest, verbose=1)\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(xtest[i].reshape(64, 64))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display encoded images\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(encoded_imgs[i].reshape(8, 8))\n",
        "    #plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(64, 64))\n",
        "    #plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tN9zPgxXG1l"
      },
      "source": [
        "\n",
        "# PCA DIMENSIONALITY REDUCTION AND REPRODUCTION\n",
        "#\n",
        "# PCA Principal Component Analysis will reduce the image dimensionally and pick out the most important data points/ pixel values\n",
        "# meaning it will reduce the data amount yet keep the 'necessary tools' to reconstruct the images but with way less data. \n",
        "# The amount of loss in the reproduced images can be increased or reduced, based on whatever level of accuracy is satisfactory. \n",
        "# From the lectures we discussed the fact that with only three pixel values or something we would be able to reproduce at an accuracy of about 50%,\n",
        "# which is..not terrible to be honest.\n",
        "# I talk about 'accuracy', in more precise terms it is the totalt variance, meaning the squared distance from the datapoints to the component(s)\n",
        "# where the least squared distance is preferable of course. \n",
        "\n",
        "pca = PCA(n_components=8*8) # Can also set a 'target accuracy' 0.8, number of components will be set automatically to achieve 80%.\n",
        "pca.fit(x)\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(len(cumsum)), cumsum)\n",
        "plt.grid()\n",
        "plt.xlabel('Principal components - amount of necessary pixels / data points')\n",
        "plt.ylabel('Explained variance - accuracy')\n",
        "plt.show()\n",
        "print('At 64x64 pixels (64 pca) we will get a 90% accuracy')\n",
        "\n",
        "x_reduced = pca.fit_transform(xtest)\n",
        "x_recovered = pca.inverse_transform(x_reduced)\n",
        "\n",
        "#print(x_reduced)\n",
        "#print(x_recovered)\n",
        "\n",
        "def display_val(x):\n",
        "  fig, ax = plt.subplots(3,5)\n",
        "  ax = ax.flatten()\n",
        "  ims = []\n",
        "  for i in range(len(ax)):\n",
        "    ax[i].imshow(xtest[i].reshape(64,64), interpolation='nearest', animated=True)\n",
        "    ax[i].xaxis.set_visible(False)\n",
        "    ax[i].yaxis.set_visible(False)\n",
        "\n",
        "display_val(xtest)\n",
        "display_val(x_recovered)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZmlkhS2XfWF"
      },
      "source": [
        "\n",
        "# unsupervised algorithm\n",
        "#kmeans is an unsupervised algorithm\n",
        "kmeans = KMeans(n_clusters=40, max_iter=10000, algorithm = 'auto', random_state=7, verbose=1)\n",
        "\n",
        "#train \n",
        "encoded_imgs = encoder.predict(xtrain)\n",
        "kmeans.fit(encoded_imgs)\n",
        "\n",
        "encoded_imgs = encoder.predict(xtest)\n",
        "ypred = kmeans.predict(encoded_imgs)\n",
        "print(ypred[0,])\n",
        "print(ytest[0,])\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", accuracy_score(ytest, ypred))\n",
        "\n",
        "cmap = ListedColormap(['lightgrey', 'silver', 'ghostwhite', 'lavender', 'wheat'])\n",
        "plt.rcParams[\"figure.figsize\"] = (8,8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efgWdqA-KdvY"
      },
      "source": [
        "\n",
        "# supervised algorithm\n",
        "\n",
        "\n",
        "ytrain_ = to_categorical(ytrain)\n",
        "ytest_ = to_categorical(ytest)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(56, activation='relu', input_shape=(8*8, ), name='hidden_layer'))\n",
        "model.add(Dense(40, activation='softmax', name='output_layer'))\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "plot_model(model, to_file='mnist_keras.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "enc_train = encoder.predict(xtrain).reshape(320,8*8)\n",
        "enc_test =encoder.predict(xtest).reshape(80,8*8)\n",
        "print(enc_train.shape)\n",
        "print(enc_test.shape)\n",
        "\n",
        "\n",
        "history = model.fit(enc_train, ytrain_, epochs=100, batch_size=32)\n",
        "test_loss, test_accu = model.evaluate(enc_test, ytest_)\n",
        "print(test_loss, test_accu)\n",
        "\n",
        "cmap = ListedColormap(['lightgrey', 'silver', 'ghostwhite', 'lavender', 'wheat'])\n",
        "plt.rcParams[\"figure.figsize\"] = (8,8)\n",
        "\n",
        "# confusion matrix\n",
        "def cm(ytest, ypred, title):\n",
        "  print(ytest.shape)\n",
        "  print(ypred.shape)\n",
        "\n",
        "  cm = confusion_matrix(ytest, ypred)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.matshow(cm, cmap=cmap)\n",
        "  \n",
        "  for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "      plt.text(x=j, y=i, s=cm[i,j], va='center', ha='center')\n",
        "  \n",
        "  plt.title(title)\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.ylabel('True label')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "ypred_train = model.predict(enc_train)\n",
        "ypred_train = np.argmax(ypred_train, axis=-1)\n",
        "cm(ytrain, ypred_train, title='Train')\n",
        "\n",
        "\n",
        "\n",
        "ypred_test = model.predict(enc_test)\n",
        "ypred_test = np.argmax(ypred_test, axis=-1)\n",
        "print(ypred_test.shape)\n",
        "print(ytest.shape)\n",
        "\n",
        "print(np.unique(ypred_test))\n",
        "print(np.unique(ytest))\n",
        "\n",
        "print('Precision score:', precision_score(ytest, ypred_test, average='macro'))\n",
        "print('Recall score   :', recall_score(ytest, ypred_test, average='macro'))\n",
        "\n",
        "cm(ytest[1:], ypred_test[1:], title='Test')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHLgZAL8YjSn"
      },
      "source": [
        "def cm(ytest, ypred, title):\n",
        "  cm = confusion_matrix(ytest, ypred)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.matshow(cm, cmap=cmap)\n",
        "  \n",
        "  for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "      plt.text(x=j, y=i, s=cm[i,j], va='center', ha='center')\n",
        "  \n",
        "  plt.title(title)\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.ylabel('True label')\n",
        "  plt.show()\n",
        "\n",
        "cm(ytrain, kmeans.predict(encoder.predict(xtrain)), title='Train')\n",
        "cm(ytest, kmeans.predict(encoder.predict(xtest)), title='Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h6CJs9KfUXF"
      },
      "source": [
        "#cross-validation  - SGD, BGD and MBGD\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}